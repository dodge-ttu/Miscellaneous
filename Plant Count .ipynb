{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Canopy Coverage Estimation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Will Dodge | 2018 | dodge.ttu@gmail.com\n",
    "\"\"\")\n",
    "print(\"=\"*100)\n",
    "print(\"=\"*100)\n",
    "print(\"begining processing....\")\n",
    "\n",
    "print(\"importing libraries...\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "# input path\n",
    "aom_extracted_path = \"C:\\\\Users\\\\dodge\\\\Desktop\\\\AOMs extracted\\\\AOM extracted sets\\\\\"\n",
    "\n",
    "# output path\n",
    "path = \"C:\\\\Users\\\\dodge\\\\Desktop\\\\AOMs extracted\\\\\"\n",
    "\n",
    "filenames = os.listdir(aom_extracted_path)\n",
    "\n",
    "print(\"reading in large aom extracted sets...\")\n",
    "images = [cv2.imread(aom_extracted_path + i) for i in filenames]\n",
    "\n",
    "print(\"reading germplasm ID data\")\n",
    "germplasm_id_set_path = \"C:\\\\Users\\\\dodge\\\\Desktop\\\\AOMs extracted\\\\mauricio_field_map_ID_only_UPDATED.csv\"\n",
    "\n",
    "df = pd.read_csv(germplasm_id_set_path, header=[0])\n",
    "\n",
    "df_long = pd.melt(df)\n",
    "\n",
    "df_long.dropna(inplace=True)\n",
    "\n",
    "print(\"germplasm ID set length is {0}\".format(len(df_long)))\n",
    "\n",
    "germplasm_id_set = [i for i in df_long[\"value\"].values]\n",
    "\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "def find_contours_and_centers(img_input):\n",
    "\n",
    "    \"\"\"\n",
    "    :param img_input: composite with AOMs extracted ready for analyisis\n",
    "    :return: a list of contours and list of contour center tuples\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"find contours and centers starting...\")\n",
    "    img_gray = cv2.cvtColor(img_input, cv2.COLOR_BGR2GRAY)\n",
    "    img_gray = cv2.GaussianBlur(img_gray, (3,3), 0)\n",
    "    (T, thresh) = cv2.threshold(img_gray, 0, 255, 0)\n",
    "    _, contours_raw, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [i for i in contours_raw if cv2.contourArea(i) > 50000]\n",
    "    contour_centers = []\n",
    "\n",
    "    for idx, c in enumerate(contours):\n",
    "        M = cv2.moments(c)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        samp_bounds = cv2.boundingRect(c)\n",
    "        contour_centers.append(((cX,cY), samp_bounds))\n",
    "\n",
    "    print(\"{0} contour centers and bounds found\".format(len(contour_centers)))\n",
    "\n",
    "    contour_centers = sorted(contour_centers, key=lambda x: x[0])\n",
    "    print(\"...done\")\n",
    "\n",
    "    return contours, contour_centers\n",
    "\n",
    "contours_all = []\n",
    "centers_and_bounds_all  = []\n",
    "\n",
    "for image_set in images:\n",
    "    contours, centers = find_contours_and_centers(image_set)\n",
    "    contours_all.append(contours)\n",
    "    centers_and_bounds_all.append(centers)\n",
    "\n",
    "grouping_sequence_all = []\n",
    "\n",
    "for idx, centers in enumerate(centers_and_bounds_all):\n",
    "    print(\"generating grouping sequence {0}\".format(idx))\n",
    "    grouping_sequence = [i for i in range(56, len(centers)+57, 56)]\n",
    "    grouping_sequence_all.append(grouping_sequence)\n",
    "\n",
    "print(\"grouping_sequence length {0}\".format(len(grouping_sequence_all)))\n",
    "\n",
    "organized_contour_centers_and_bounds_all = []\n",
    "\n",
    "for idx1, (grouping_sequence, centers_and_bounds) in enumerate(zip(grouping_sequence_all, centers_and_bounds_all)):\n",
    "    print(\"organizing contour centers for image set {0}\".format(idx1))\n",
    "    print(\"=\" * 100)\n",
    "    print(\"=\" * 100)\n",
    "    organized_contour_centers_and_bounds = []\n",
    "    for idx, i in enumerate(grouping_sequence):\n",
    "        print(\"organizing contour centers for tier {0}\".format(idx))\n",
    "        if idx == 0:\n",
    "            row = centers_and_bounds[:i]\n",
    "            row = sorted(row, key=lambda x: x[0][1])\n",
    "            organized_contour_centers_and_bounds.extend(row)\n",
    "        else:\n",
    "            row = centers_and_bounds[grouping_sequence[idx-1]:i]\n",
    "            row = sorted(row, key=lambda x: x[0][1])\n",
    "            organized_contour_centers_and_bounds.extend(row)\n",
    "\n",
    "    organized_contour_centers_and_bounds_all.append(organized_contour_centers_and_bounds)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"organized contour center length {0}\".format(len(organized_contour_centers_and_bounds_all)))\n",
    "print(\"=\"*100)\n",
    "\n",
    "\n",
    "def make_row_tier_tags(number_of_tiers, number_of_rows):\n",
    "\n",
    "    \"\"\"\n",
    "    :param number_of_tiers: number of tiers in map\n",
    "    :param number_of_rows: number of rows in map\n",
    "    :return: list of of IDs that are organized for the purpose of \"pasting\" on our images.\n",
    "    \"\"\"\n",
    "\n",
    "    row_tier_tuple_list = []\n",
    "\n",
    "    for i in range(1, number_of_tiers + 1, 1):\n",
    "        if i == 56:\n",
    "            for j in range(1, ((number_of_rows + 1) - 2), 1):\n",
    "                row_tier_tuple_list.append(\"row-{0}__tier-{1}\".format(j, i))\n",
    "        else:\n",
    "            for j in range(1, number_of_rows + 1, 1):\n",
    "                row_tier_tuple_list.append(\"row-{0}__tier-{1}\".format(j, i))\n",
    "\n",
    "    return row_tier_tuple_list\n",
    "\n",
    "\n",
    "row_tier_tags = make_row_tier_tags(25, 56)\n",
    "\n",
    "del row_tier_tags[1344:1345]\n",
    "\n",
    "def put_id_on_sample_map(img_input, contour_centers_and_bounds, id_set, row_tier_list):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    :param img_input:\n",
    "    :param contour_centers_and_bounds:\n",
    "    :return: Nothing. The main composite is marked.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for center, id, row_tier in zip(contour_centers_and_bounds, id_set, row_tier_list):\n",
    "        cv2.putText(img_input, str(id), (center[0][0]+120, center[0][1]+40), font, .6, (200, 0, 0), 1)\n",
    "        cv2.putText(img_input, str(row_tier), (center[0][0] - 240, center[0][1] + 40), font, .6, (200, 0, 0), 1)\n",
    "\n",
    "\n",
    "for idx, (org_centers_and_bounds, i) in enumerate(zip(organized_contour_centers_and_bounds_all, images)):\n",
    "    print(\"tagging image set {0}\".format(idx))\n",
    "    put_id_on_sample_map(i, org_centers_and_bounds, germplasm_id_set, row_tier_tags)\n",
    "\n",
    "def make_sample_images(img_input, contour_bounds):\n",
    "\n",
    "    \"\"\"\n",
    "    :param img_input: masked composite ready for processing\n",
    "    :return: list of image slices derived from cv2.boundingRect()\n",
    "    \"\"\"\n",
    "\n",
    "    smple_images = []\n",
    "\n",
    "    for i in contour_bounds:\n",
    "        x = i[1][0]\n",
    "        y = i[1][1]\n",
    "        w = i[1][2]\n",
    "        h = i[1][3]\n",
    "\n",
    "        img = img_input[y:(y + h), x:(x + w)]\n",
    "        #cv2.rectangle(img_input, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        smple_images.append(img)\n",
    "\n",
    "    return smple_images\n",
    "\n",
    "\n",
    "sample_image_sets_all = []\n",
    "\n",
    "for idx, (i,j) in enumerate(zip(images, organized_contour_centers_and_bounds_all)):\n",
    "    print(\"generating image sample set {0}\".format(idx))\n",
    "    sample_images = make_sample_images(i, j)\n",
    "    sample_image_sets_all.append(sample_images)\n",
    "\n",
    "print(\"generating image stacks for sample sets\")\n",
    "\n",
    "min_set_length = min([len(i) for i in sample_image_sets_all])\n",
    "\n",
    "print(\"minimum set length is {0}\".format(min_set_length))\n",
    "\n",
    "unbound_sample_image_stacks_all = []\n",
    "\n",
    "for i in range(min_set_length - 1):\n",
    "    stack_set = []\n",
    "    for j in sample_image_sets_all:\n",
    "        img = cv2.resize(j[i], (600, 100))\n",
    "        stack_set.append(img)\n",
    "\n",
    "    unbound_sample_image_stacks_all.append(stack_set)\n",
    "\n",
    "bound_stack_sets = []\n",
    "\n",
    "for i in unbound_sample_image_stacks_all:\n",
    "    img_stacks = np.vstack(i)\n",
    "    bound_stack_sets.append(img_stacks)\n",
    "\n",
    "for idx, (name, sample_image_set, aom_extracted_image) in enumerate(zip(filenames, sample_image_sets_all, images)):\n",
    "    directory = path + name + \"_folder\"\n",
    "    print(\"writing image set {0}\".format(idx))\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        for (germplasm_id, img, row_tier) in zip(germplasm_id_set, sample_image_set, row_tier_tags):\n",
    "            cv2.imwrite(os.path.join(directory, (germplasm_id + \"_\" + row_tier + \".tif\")), img)\n",
    "\n",
    "directory_maps = os.path.join(path, \"aom_maps\\\\\")\n",
    "if not os.path.exists(directory_maps):\n",
    "    os.makedirs(directory_maps)\n",
    "\n",
    "for (name, aom_extracted_image) in zip(filenames, images):\n",
    "    print(\"writing map {0}\".format(name))\n",
    "    cv2.imwrite(os.path.join(directory_maps, (name + \"_map.tif\")), aom_extracted_image)\n",
    "\n",
    "directory_for_stacks_all = path + \"2018_sample_image_stacks\\\\\"\n",
    "print(\"making stack image set directory...\")\n",
    "if not os.path.exists(directory_for_stacks_all):\n",
    "    os.makedirs(directory_for_stacks_all)\n",
    "\n",
    "print(\"writing stack image sets...\")\n",
    "\n",
    "for germplasm_id, row_tier, i in zip(germplasm_id_set, row_tier_tags, bound_stack_sets):\n",
    "    cv2.imwrite(directory_for_stacks_all + germplasm_id + \"_\" + row_tier + \"_\" + \"_stack.png\", i)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"clearing objects from environment to free up memory...\")\n",
    "\n",
    "del centers_and_bounds_all, contours_all, images, organized_contour_centers_and_bounds_all\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"generating growth data sets for each variety...\")\n",
    "\n",
    "\n",
    "def green_diff_mask(sample_image):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns an image mask and pixel count for pixels where the green value is greater than the blue and red (B < G > R)\n",
    "\n",
    "    :param sample_image:\n",
    "    :return: masked image and pixel count\n",
    "    \"\"\"\n",
    "\n",
    "    img_original = sample_image.copy()\n",
    "    b, g, r = cv2.split(sample_image)\n",
    "    # mask = np.where(np.logical_and((img[:,:,1] > img[:,:,0]), (img[:,:,1] > img[:,:,2])))\n",
    "\n",
    "    # b = b.astype(np.int16)\n",
    "    # g = g.astype(np.int16)\n",
    "    # r = r.astype(np.int16)\n",
    "\n",
    "    mask = np.where(np.logical_and(g > b, g > r))\n",
    "\n",
    "    x, y = mask\n",
    "    x = x.tolist()\n",
    "    y = y.tolist()\n",
    "    marks = [(x, y) for (x, y) in zip(x, y)]\n",
    "\n",
    "    img_marked = sample_image.copy()\n",
    "\n",
    "    for i in marks:\n",
    "        # cv2.circle(img, (i[1], i[0]), 1, (255,255,255), 1)\n",
    "        img_marked[i] = (255, 255, 255)\n",
    "\n",
    "    img_marked = cv2.cvtColor(img_marked, cv2.COLOR_BGR2GRAY)\n",
    "    (T, mask) = cv2.threshold(img_marked, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    img_out = cv2.bitwise_and(img_original, img_original, mask=mask)\n",
    "\n",
    "    return img_out, len(marks)\n",
    "\n",
    "\n",
    "def plant_count(green_diff_morph):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    green_diff_morph_gray = cv2.cvtColor(green_diff_morph, cv2.COLOR_BGR2GRAY)\n",
    "    (T, thresh) = cv2.threshold(green_diff_morph, 1, 255, cv2.THRESH_BINARY)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, (5,5))\n",
    "    (_, plants, _) = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    return green_diff_morph\n",
    "\n",
    "\n",
    "sample_image_set_directories = [path + name + \"_folder\\\\\" for name in filenames]\n",
    "\n",
    "sample_image_filenames_all = [os.listdir(directory_path) for directory_path in sample_image_set_directories]\n",
    "\n",
    "sample_image_filepaths_all = []\n",
    "\n",
    "for directory_path, samp_filenames in zip(sample_image_set_directories, sample_image_filenames_all):\n",
    "    samp_filepaths = [os.path.join(directory_path, i) for i in samp_filenames]\n",
    "    sample_image_filepaths_all.append(samp_filepaths)\n",
    "\n",
    "sample_images_all = []\n",
    "\n",
    "for idx, i in enumerate(sample_image_filepaths_all):\n",
    "    print(\"reading in sample image set {0}\".format(idx))\n",
    "    img_set = [cv2.imread(j) for j in i]\n",
    "    sample_images_all.append(img_set)\n",
    "\n",
    "green_diff_mask_sets_all = []\n",
    "\n",
    "for idx, i in enumerate(sample_images_all):\n",
    "    print(\"applying green diff mask in sample image set {0}\".format(idx))\n",
    "    green_diff_sets = [green_diff_mask(j) for j in i]\n",
    "    green_diff_mask_sets_all.append(green_diff_sets)\n",
    "\n",
    "for idx, (name, sample_image_set) in enumerate(zip(filenames, green_diff_mask_sets_all)):\n",
    "    directory = path + \"GREEN_DIFF_\" + name + \"_folder\\\\\"\n",
    "    print(\"writing image set {0}\".format(idx))\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        for (germplasm_id, img, row_tier) in zip(germplasm_id_set, sample_image_set, row_tier_tags):\n",
    "            cv2.imwrite(os.path.join(directory, (germplasm_id + \"_\" + row_tier + \".tif\")), img[0])\n",
    "\n",
    "\n",
    "flight_date_list = [i[:10] for i in filenames]\n",
    "\n",
    "dict = {\"flight_date\": pd.to_datetime(flight_date_list)}\n",
    "\n",
    "df_growth_data = pd.DataFrame(dict)\n",
    "\n",
    "unbound_green_diff_pixel_data_all = []\n",
    "\n",
    "for i in range(min_set_length - 1):\n",
    "    stack_set = []\n",
    "    for j in green_diff_mask_sets_all:\n",
    "        h, w, c = j[i][0].shape\n",
    "        green_diff_pixel_count = j[i][1]\n",
    "        total_sample_pixel_count = h * w\n",
    "        stack_set.append((green_diff_pixel_count, total_sample_pixel_count))\n",
    "\n",
    "    unbound_green_diff_pixel_data_all.append(stack_set)\n",
    "\n",
    "for i, j in zip(germplasm_id_set, unbound_green_diff_pixel_data_all):\n",
    "        green_diff_pix_count = [k[0] for k in j]\n",
    "        total_smple_pixel_count = [k[1] for k in j]\n",
    "        percent_canopy_cover = [a/b for a,b in zip(green_diff_pix_count, total_smple_pixel_count)]\n",
    "        df_growth_data[i] = percent_canopy_cover\n",
    "\n",
    "df_growth_data.set_index(\"flight_date\", inplace=True)\n",
    "\n",
    "plt.figure(figsize=(24,18))\n",
    "for i in list(df_growth_data):\n",
    "    plt.plot(df_growth_data[i])\n",
    "\n",
    "plt.savefig(os.path.join(path, \"all_germ_growth_plot.png\"))\n",
    "\n",
    "plot_sets = df_growth_data[list(df_growth_data)[:600]]\n",
    "\n",
    "fig, axes = plt.subplots(20, 30, figsize=(24, 18), sharey=True, sharex=True)\n",
    "fig.subplots_adjust(hspace=.3, wspace=.175)\n",
    "for ax, vector_name in zip(axes.ravel(), list(plot_sets)):\n",
    "    ax.plot(plot_sets[vector_name], \"r-\")\n",
    "    #ax.set_title(vector_name, {\"fontsize\":3})\n",
    "    ax.tick_params(axis='x', labelrotation=90, labelsize=2)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.savefig(os.path.join(path, \"small_multiple_germ_growth_plot.png\"))\n",
    "\n",
    "print(\"TT Guns Up TT\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
